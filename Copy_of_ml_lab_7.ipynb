{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavitraa0625/ML-LAB/blob/main/Copy_of_ml_lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNB45flYRx8M",
        "outputId": "9741bc3f-bd80-4d7d-8e29-f7b344c8322c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extraction completed!\n",
            "Top-level folders: ['PlantVillage-Dataset']\n",
            "Using dataset folder: /content/PlantVillage/PlantVillage-Dataset\n",
            "Sample classes: ['create_data_distribution.py', 'generate_data_color-50-50.sh', 'README.md', 'generate_data_color-80-20.sh', 'slurm-476493.out', 'slurm-476489.out', 'slurm-476485.out', 'generate_data_color-60-40.sh', '.git', 'slurm-476490.out']\n",
            "CSV file created at: /content/drive/MyDrive/plant_dataset.csv\n",
            "                                          image_path label\n",
            "0  /content/PlantVillage/PlantVillage-Dataset/dat...    34\n",
            "1  /content/PlantVillage/PlantVillage-Dataset/dat...    34\n",
            "2  /content/PlantVillage/PlantVillage-Dataset/dat...    34\n",
            "3  /content/PlantVillage/PlantVillage-Dataset/dat...    34\n",
            "4  /content/PlantVillage/PlantVillage-Dataset/dat...    34\n",
            "Total images found: 182214\n",
            "Class distribution:\n",
            " label\n",
            "Orange___Haunglongbing_(Citrus_greening)    16521\n",
            "Tomato___Tomato_Yellow_Leaf_Curl_Virus      16071\n",
            "Soybean___healthy                           15270\n",
            "Peach___Bacterial_spot                       6891\n",
            "Tomato___Bacterial_spot                      6381\n",
            "                                            ...  \n",
            "14                                            146\n",
            "36                                            143\n",
            "2                                              99\n",
            "17                                             95\n",
            "22                                             41\n",
            "Name: count, Length: 76, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "# PlantVillage CSV Generator\n",
        "# --------------------------\n",
        "\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1️⃣ Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Set ZIP file path in Drive\n",
        "zip_path = '/content/drive/MyDrive/PlantVillage-Dataset.zip'\n",
        "extract_path = '/content/PlantVillage'\n",
        "\n",
        "# 3️⃣ Extract ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction completed!\")\n",
        "\n",
        "# 4️⃣ Automatically locate the folder containing class subfolders\n",
        "# Usually inside 'PlantVillage' folder\n",
        "subfolders = os.listdir(extract_path)\n",
        "print(\"Top-level folders:\", subfolders)\n",
        "\n",
        "# Assuming the images are inside the first folder\n",
        "dataset_path = os.path.join(extract_path, subfolders[0])\n",
        "print(\"Using dataset folder:\", dataset_path)\n",
        "print(\"Sample classes:\", os.listdir(dataset_path)[:10])\n",
        "\n",
        "# 5️⃣ Generate CSV from image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_paths.append(os.path.join(root, file))\n",
        "            labels.append(os.path.basename(root))  # folder name = label\n",
        "\n",
        "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "\n",
        "# 6️⃣ Save CSV to Drive\n",
        "csv_path = '/content/drive/MyDrive/plant_dataset.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at: {csv_path}\")\n",
        "print(df.head())\n",
        "print(\"Total images found:\", len(df))\n",
        "print(\"Class distribution:\\n\", df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/plant_dataset.csv')\n",
        "\n",
        "# Split 80% train, 20% test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv = '/content/drive/MyDrive/plant_train.csv'\n",
        "test_csv = '/content/drive/MyDrive/plant_test.csv'\n",
        "\n",
        "train_df.to_csv(train_csv, index=False)\n",
        "test_df.to_csv(test_csv, index=False)\n",
        "\n",
        "print(\"Train CSV saved at:\", train_csv)\n",
        "print(\"Test CSV saved at:\", test_csv)\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Test samples:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ercWpGsPSmrD",
        "outputId": "e72dcd3a-f0fc-4737-884d-830262f01215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train CSV saved at: /content/drive/MyDrive/plant_train.csv\n",
            "Test CSV saved at: /content/drive/MyDrive/plant_test.csv\n",
            "Train samples: 145771\n",
            "Test samples: 36443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load CSV\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/plant_train.csv')\n",
        "test_df  = pd.read_csv('/content/drive/MyDrive/plant_test.csv')\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "print(\"Class distribution in train:\\n\", train_df['label'].value_counts())\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_enc'] = le.fit_transform(train_df['label'])\n",
        "test_df['label_enc']  = le.transform(test_df['label'])\n",
        "\n",
        "# Features are image paths, target is label_enc\n",
        "X_train = train_df['image_path']\n",
        "y_train = train_df['label_enc']\n",
        "X_test  = test_df['image_path']\n",
        "y_test  = test_df['label_enc']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdfcH2crSrqu",
        "outputId": "367c62ad-81f0-448a-dfad-7c3ee6fa8d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (145771, 2)\n",
            "Test shape: (36443, 2)\n",
            "Class distribution in train:\n",
            " label\n",
            "Orange___Haunglongbing_(Citrus_greening)    13217\n",
            "Tomato___Tomato_Yellow_Leaf_Curl_Virus      12857\n",
            "Soybean___healthy                           12216\n",
            "Peach___Bacterial_spot                       5513\n",
            "Tomato___Bacterial_spot                      5105\n",
            "                                            ...  \n",
            "14                                            117\n",
            "36                                            114\n",
            "2                                              79\n",
            "17                                             76\n",
            "22                                             33\n",
            "Name: count, Length: 76, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZObunxzFS5hD",
        "outputId": "d2deb630-a0df-4cd4-b5aa-798c5d1a5a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "rRM4WmkXTZ16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the full CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/plant_dataset.csv')\n",
        "\n",
        "# Random sample 5000 images for faster processing\n",
        "df_sample = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split into train/test 80:20\n",
        "train_df, test_df = train_test_split(df_sample, test_size=0.2, stratify=df_sample['label'], random_state=42)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_enc'] = le.fit_transform(train_df['label'])\n",
        "test_df['label_enc']  = le.transform(test_df['label'])\n",
        "\n",
        "X_train_paths = train_df['image_path']\n",
        "y_train = train_df['label_enc']\n",
        "X_test_paths  = test_df['image_path']\n",
        "y_test  = test_df['label_enc']\n",
        "\n",
        "print(\"Train samples:\", len(X_train_paths))\n",
        "print(\"Test samples:\", len(X_test_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tAzHhu4TjVO",
        "outputId": "7a8120e3-bac2-4f2d-8be7-8a5a0400ecdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4000\n",
            "Test samples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and resize images\n",
        "def load_and_preprocess(img_paths, size=(32,32)):\n",
        "    features = []\n",
        "    for path in img_paths:\n",
        "        img = cv2.imread(path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, size)\n",
        "            features.append(img.flatten())\n",
        "    return np.array(features)\n",
        "\n",
        "# Convert train/test images to features\n",
        "X_train_features = load_and_preprocess(X_train_paths)\n",
        "X_test_features  = load_and_preprocess(X_test_paths)\n",
        "\n",
        "print(\"Feature shapes:\", X_train_features.shape, X_test_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bOojFF9TmfX",
        "outputId": "1165f660-fa7f-480a-ff4c-d8ac22f06b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shapes: (4000, 3072) (1000, 3072)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize RandomForest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# RandomizedSearchCV\n",
        "rf_random = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
        "                               n_iter=3, scoring='accuracy', cv=3,\n",
        "                               random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"Best RandomForest params:\", rf_random.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkwkuezrTqMj",
        "outputId": "df427b55-beac-45e8-ac08-1e1233db53e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForest params: {'n_estimators': 150, 'min_samples_split': 10, 'max_depth': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load full CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/plant_dataset.csv')\n",
        "\n",
        "# Random sample 5000 images\n",
        "df_sample = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split into train/test 80:20\n",
        "train_df, test_df = train_test_split(df_sample, test_size=0.2,\n",
        "                                     stratify=df_sample['label'], random_state=42)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_enc'] = le.fit_transform(train_df['label'])\n",
        "test_df['label_enc']  = le.transform(test_df['label'])\n",
        "\n",
        "X_train_paths = train_df['image_path']\n",
        "y_train = train_df['label_enc']\n",
        "X_test_paths  = test_df['image_path']\n",
        "y_test  = test_df['label_enc']\n",
        "\n",
        "print(\"Train samples:\", len(X_train_paths))\n",
        "print(\"Test samples:\", len(X_test_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HE3YII_UILo",
        "outputId": "8d00ade2-8f04-46ea-ba48-5efcfad0e845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4000\n",
            "Test samples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess(img_paths, size=(16,16)):\n",
        "    features = []\n",
        "    for path in img_paths:\n",
        "        img = cv2.imread(path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, size)\n",
        "            features.append(img.flatten())\n",
        "    return np.array(features)\n",
        "\n",
        "X_train_features = load_and_preprocess(X_train_paths)\n",
        "X_test_features  = load_and_preprocess(X_test_paths)\n",
        "\n",
        "print(\"Feature shapes:\", X_train_features.shape, X_test_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQOL1rfUdChc",
        "outputId": "81dc983c-4322-4394-b107-cf0c48fa196a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shapes: (4000, 768) (1000, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf_random = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
        "                               n_iter=3, scoring='accuracy', cv=2,\n",
        "                               random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"Best RandomForest params:\", rf_random.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_vhywnBVOx2",
        "outputId": "1e395101-7a8d-4bdd-9dab-9d72db4e7dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForest params: {'n_estimators': 150, 'min_samples_split': 10, 'max_depth': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Optimized classifier list\n",
        "classifiers = {\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': rf_random.best_estimator_,\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'NaiveBayes': GaussianNB(),\n",
        "    # Optional slower classifiers (uncomment if needed)\n",
        "    # 'SVM': SVC(),\n",
        "    # 'XGBoost': xgb.XGBClassifier(eval_metric='mlogloss'),\n",
        "    # 'CatBoost': CatBoostClassifier(verbose=0),\n",
        "    # 'MLP': MLPClassifier(max_iter=300)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_features, y_train)\n",
        "    y_train_pred = clf.predict(X_train_features)\n",
        "    y_test_pred  = clf.predict(X_test_features)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Train Accuracy': round(accuracy_score(y_train, y_train_pred), 4),\n",
        "        'Test Accuracy': round(accuracy_score(y_test, y_test_pred), 4)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hCpFmrInVAG",
        "outputId": "32d88b0c-cb4c-45a7-edba-26be1241461b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Model  Train Accuracy  Test Accuracy\n",
            "0  DecisionTree          0.9990          0.175\n",
            "1  RandomForest          0.9962          0.381\n",
            "2      AdaBoost          0.1442          0.145\n",
            "3    NaiveBayes          0.1655          0.080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce features to 50 dimensions\n",
        "pca = PCA(n_components=50, random_state=42)\n",
        "X_pca = pca.fit_transform(X_train_features)\n",
        "\n",
        "print(\"PCA reduced feature shape:\", X_pca.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNAoJqLOn3-5",
        "outputId": "721f12ed-bfd7-4f0a-c398-75541940ae87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA reduced feature shape: (4000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "\n",
        "# Agglomerative clustering\n",
        "agglo = AgglomerativeClustering(n_clusters=10, linkage='ward')  # You can change n_clusters\n",
        "agglo_labels = agglo.fit_predict(X_pca)\n",
        "\n",
        "# Count samples per cluster\n",
        "unique, counts = np.unique(agglo_labels, return_counts=True)\n",
        "print(\"Agglomerative cluster distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBpIwAdk2GKh",
        "outputId": "e03003fb-abe7-4114-8998-13035bdaef4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agglomerative cluster distribution: {np.int64(0): np.int64(401), np.int64(1): np.int64(529), np.int64(2): np.int64(182), np.int64(3): np.int64(688), np.int64(4): np.int64(397), np.int64(5): np.int64(319), np.int64(6): np.int64(359), np.int64(7): np.int64(445), np.int64(8): np.int64(337), np.int64(9): np.int64(343)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# DBSCAN parameters (tune eps for your dataset)\n",
        "dbscan = DBSCAN(eps=15, min_samples=5)  # eps may need tuning\n",
        "dbscan_labels = dbscan.fit_predict(X_pca)\n",
        "\n",
        "# Count samples per cluster\n",
        "unique, counts = np.unique(dbscan_labels, return_counts=True)\n",
        "print(\"DBSCAN cluster distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfbBtc202Jhx",
        "outputId": "7132cf1d-b9db-45c9-a63c-29561247aec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBSCAN cluster distribution: {np.int64(-1): np.int64(4000)}\n"
          ]
        }
      ]
    }
  ]
}